{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CEE 690-02\n",
    "\n",
    "# Environmental Spatial Data Analysis\n",
    "\n",
    "# Lecture 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Homework #3 clarification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In problem #1 you will need to write your own function to read in the ArcASCII files into Python the \"hard way\". See Lecture 5 to understand what I mean by the \"hard way\". Solutions that use rasterio will not receive full credit for this problem. It is important to understand what is happening under the hood (at least once!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Possible project ideas\n",
    "\n",
    "* Develop a new dataset by harnessing other data using the methods discussed in this course\n",
    "* Build a software package for spatial analysis. \n",
    "* Use spatial analysis to answer a research question\n",
    "* Many, many more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Key requirements for projects:\n",
    "\n",
    "* It needs to bring together multiple topics that we covered throughout the course\n",
    "* It has to be a substantial contribution (there are 4 members per team...)\n",
    "* The focus must be using environmental/earth data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Analyzing environmental data\n",
    "\n",
    "Let's take all that we have learned over the past few weeks and do some actual science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Output from climate models\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b1/Global_Climate_Model.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "'<iframe width=\"939\" height=\"528\" src=\"https://www.youtube.com/embed/toCFqOGVs54\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# GFDL climate model: AM4\n",
    "\n",
    "<img src=\"https://www.gfdl.noaa.gov/wp-content/uploads/2018/10/air_surface_temp_cm3.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Compare to ERA-Interim reanalysis\n",
    "\n",
    "<img src=\"https://icdc.cen.uni-hamburg.de/fileadmin/_processed_/0/f/csm_ERAIN_SFC00_6H_2T_167_monmean_24bb5a1b24.png\" width=\"400\">\n",
    "\n",
    "Assume that it counts as observations. However, know that that assumption can be a stretch. So when using these data to validate climate or weather model output always be cognizant of errors in the observations themselves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Read in ERA-Interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "#Let's read in the annual mean precipitation, wind speed, temperature, and pressure from ERA-Interim\n",
    "file = '/data/era-interim/era_interim_monthly_197901_201512_upscaled.nc_ann'\n",
    "#Let's read in the annual mean precipitation, specific humidity, temperature, and pressure from ERA-Interim\n",
    "fp = nc.Dataset(file)\n",
    "output_era = {}\n",
    "vars = ['precip','evap','t_ref','ps']\n",
    "for var in vars:\n",
    "    if var in ['evap','precip']:\n",
    "        output_era[var] = 365*fp[var][:]\n",
    "    if var == 't_ref':\n",
    "        output_era['t_ref'] = 273.15 + fp['t2m'][:]\n",
    "    if var == 'ps':\n",
    "        output_era['ps'] = 100*fp['p_sfc'][:]\n",
    "    times = fp['time']\n",
    "    output_era['dates'] = nc.num2date(times[:],units=times.units,calendar=times.calendar)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Make some spatial plots of ERA-Interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#Let's show some basic statistics of this data (subplot,mean)\n",
    "#Let's create a dictionary for colormaps\n",
    "info = {'precip':{'cmap':'terrain','title':'Precipitation (mm/year)'},\n",
    "        't_ref':{'cmap':'RdBu_r','title':'Temperature (K)'},\n",
    "        'evap':{'cmap':'Blues','title':'Evaporation (mm/year)'},\n",
    "        'ps':{'cmap':'jet','title':'Pressure (Pa)'}}\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "for var in vars:\n",
    "    plt.subplot(2,2,vars.index(var)+1)\n",
    "    plt.imshow(np.flipud(np.mean(output_era[var],axis=0)),cmap=plt.get_cmap(info[var]['cmap']))\n",
    "    cb = plt.colorbar(shrink=0.8,orientation='horizontal',pad=0.03)\n",
    "    cb.ax.tick_params(labelsize=15,rotation=30)\n",
    "    plt.title(info[var]['title'],fontsize=20)\n",
    "    plt.axis('off')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Make some time series plots of ERA-Interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Spatial mean time series\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "for var in vars:\n",
    "    plt.subplot(2,2,vars.index(var)+1)\n",
    "    data = np.mean(np.mean(output_era[var],axis=1),axis=1)\n",
    "    plt.plot(output_era['dates'],data,lw=3)\n",
    "    plt.title(info[var]['title'],fontsize=20)\n",
    "    plt.xticks(fontsize=15,rotation=35)\n",
    "    plt.yticks(fontsize=15)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Note**: The spatial averaging that we used to create the time series is actually wrong. What could be the issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We have to do a areal weighted average since the Earth is not flat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Read in GFDL AM4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import dateutil\n",
    "#Let's read in the annual mean precipitation, specific humidity, temperature, and pressure from ERA-Interim\n",
    "output_gfdl = {}\n",
    "for var in vars:\n",
    "    file = '/data/GFDL/atmos.1980-2014.%s.nc_ann' % var\n",
    "    fp = nc.Dataset(file)\n",
    "    output_gfdl[var] = fp[var][:]\n",
    "    if var in ['evap','precip']:\n",
    "        output_gfdl[var] = 365*24*3600*output_gfdl[var]\n",
    "    times = fp['time']\n",
    "    output_gfdl['dates'] = nc.num2date(times[:],units=times.units,calendar=times.calendar)\n",
    "    #subtract one year from dates, error in output\n",
    "    output_gfdl['dates'] = output_gfdl['dates']\n",
    "    fp.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Make some spatial plots of GFDL AM4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's show some basic statistics of this data (subplot,mean)\n",
    "#Let's create a dictionary for colormaps\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "for var in vars:\n",
    "    plt.subplot(2,2,vars.index(var)+1)\n",
    "    plt.imshow(np.flipud(np.mean(output_gfdl[var],axis=0)),cmap=plt.get_cmap(info[var]['cmap']))\n",
    "    cb = plt.colorbar(shrink=0.8,orientation='horizontal',pad=0.03)\n",
    "    cb.ax.tick_params(labelsize=15,rotation=30)\n",
    "    plt.title(info[var]['title'],fontsize=20)\n",
    "    plt.axis('off')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Make some time series plots of GFDL AM4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Spatial mean time series\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "for var in vars:\n",
    "    plt.subplot(2,2,vars.index(var)+1)\n",
    "    data = np.mean(np.mean(output_gfdl[var],axis=1),axis=1)\n",
    "    plt.plot(output_gfdl['dates'],data,lw=3)\n",
    "    plt.title(info[var]['title'],fontsize=20)\n",
    "    plt.xticks(fontsize=15,rotation=35)\n",
    "    plt.yticks(fontsize=15)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compare spatial plots side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Compare the maps\n",
    "#Let's show some basic statistics of this data (subplot,mean)\n",
    "#Let's create a dictionary for colormaps\n",
    "fig = plt.figure(figsize=(14,16))\n",
    "i = 0\n",
    "for var in vars:\n",
    "    i += 1\n",
    "    plt.subplot(4,3,i)\n",
    "    data1 = np.flipud(np.mean(output_era[var],axis=0))\n",
    "    vmin = np.min(data1)\n",
    "    vmax = np.max(data1)\n",
    "    plt.imshow(data1,vmin=vmin,vmax=vmax,cmap=plt.get_cmap(info[var]['cmap']))\n",
    "    plt.title('ERA-Interim',fontsize=20)\n",
    "    plt.ylabel(info[var]['title'],fontsize=18)\n",
    "    cb = plt.colorbar(orientation='horizontal',shrink=0.8,pad=0.03)\n",
    "    cb.ax.tick_params(labelsize=15,rotation=30)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    i += 1\n",
    "    plt.subplot(4,3,i)\n",
    "    data2 = np.flipud(np.mean(output_gfdl[var],axis=0))\n",
    "    plt.imshow(data2,vmin=vmin,vmax=vmax,cmap=plt.get_cmap(info[var]['cmap']))\n",
    "    plt.title('GFDL AM4',fontsize=20)\n",
    "    cb = plt.colorbar(orientation='horizontal',shrink=0.8,pad=0.03)\n",
    "    cb.ax.tick_params(labelsize=15,rotation=30)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    i += 1\n",
    "    plt.subplot(4,3,i)\n",
    "    data = data2-data1\n",
    "    vmin = np.mean(data) - 2*np.std(data)\n",
    "    vmax = np.mean(data) + 2*np.std(data)\n",
    "    plt.imshow(data,cmap=plt.get_cmap('RdBu_r'),vmin=vmin,vmax=vmax)\n",
    "    plt.title('GFDL AM4 - ERA-Interim',fontsize=20)\n",
    "    cb = plt.colorbar(orientation='horizontal',shrink=0.8,pad=0.03)\n",
    "    cb.ax.tick_params(labelsize=15,rotation=30)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compare annual time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Compare the time series\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "i = 0\n",
    "for var in vars:\n",
    "    i += 1\n",
    "    plt.subplot(2,2,i)\n",
    "    data = np.mean(np.mean(output_gfdl[var],axis=1),axis=1)\n",
    "    plt.plot(output_gfdl['dates'],data,lw=3)\n",
    "    data = np.mean(np.mean(output_era[var],axis=1),axis=1)\n",
    "    plt.plot(output_era['dates'],data,lw=3)\n",
    "    plt.title(info[var]['title'],fontsize=20)\n",
    "    plt.xticks(fontsize=15,rotation=35)\n",
    "    plt.yticks(fontsize=15)\n",
    "    if i == 1:plt.legend(['GFDL AM4','ERA-Interim'],fontsize=10)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How can we more quantitavely compare time series or spatial maps?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Performance metrics/Statistical tests\n",
    "\n",
    "This is not going to be exhaustive but it should give some insight into the basics of model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bias\n",
    "\n",
    "#### $bias = \\frac{1}{n}\\sum_i^n \\left(x_i - y_i\\right)$\n",
    "\n",
    "where $x_i$ is the observation value and $y_i$ is the model value at time or location $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bias(x,y):\n",
    "    return np.mean(x - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "dates_gfdl = output_gfdl['dates']\n",
    "dates_era = output_era['dates']\n",
    "m_gfdl = (dates_gfdl >= datetime.datetime(1980,1,1)) & (dates_gfdl <= datetime.datetime(2014,1,31))\n",
    "m_era = (dates_era >= datetime.datetime(1980,1,1)) & (dates_era <= datetime.datetime(2014,1,31))\n",
    "#Compare the time series\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "i = 0\n",
    "for var in vars:\n",
    "    i += 1\n",
    "    plt.subplot(2,2,i)\n",
    "    data1 = np.mean(np.mean(output_gfdl[var][m_gfdl,:,:],axis=1),axis=1)\n",
    "    plt.plot(output_gfdl['dates'][m_gfdl],data1,lw=3)\n",
    "    data2 = np.mean(np.mean(output_era[var][m_era,:,:],axis=1),axis=1)\n",
    "    plt.plot(output_era['dates'][m_era],data2,lw=3)\n",
    "    plt.title(info[var]['title'],fontsize=20)\n",
    "    plt.xticks(fontsize=15,rotation=35)\n",
    "    plt.yticks(fontsize=15)\n",
    "    #Calculate absolute bias\n",
    "    metric = calculate_bias(data1,data2)\n",
    "    plt.text(0.3,0.9,'bias: %.2f' % metric,horizontalalignment='center',verticalalignment='center', \n",
    "             transform=plt.gca().transAxes,fontsize=20)\n",
    "    if i == 1:plt.legend(['GFDL AM4','ERA-Interim'],fontsize=10)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Root mean squared error (RMSE)\n",
    "\n",
    "#### $rmse = \\sqrt{\\frac{1}{n}\\sum_i^n (x_i - y_i)^2}$\n",
    "\n",
    "where $x_i$ is the observation value and $y_i$ is the model value at time or location $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(x,y):\n",
    "    return np.mean((x - y)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the time series\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "i = 0\n",
    "for var in vars:\n",
    "    i += 1\n",
    "    plt.subplot(2,2,i)\n",
    "    data1 = np.mean(np.mean(output_gfdl[var][m_gfdl,:,:],axis=1),axis=1)\n",
    "    plt.plot(output_gfdl['dates'][m_gfdl],data1,lw=3)\n",
    "    data2 = np.mean(np.mean(output_era[var][m_era,:,:],axis=1),axis=1)\n",
    "    plt.plot(output_era['dates'][m_era],data2,lw=3)\n",
    "    plt.title(info[var]['title'],fontsize=20)\n",
    "    plt.xticks(fontsize=15,rotation=35)\n",
    "    plt.yticks(fontsize=15)\n",
    "    #Calculate root squared mean error\n",
    "    metric = calculate_rmse(data1,data2)\n",
    "    plt.text(0.3,0.9,'rmse: %.2f' % metric,horizontalalignment='center',verticalalignment='center', \n",
    "             transform=plt.gca().transAxes,fontsize=20)\n",
    "    if i == 1:plt.legend(['GFDL AM4','ERA-Interim'],fontsize=10)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear correlation\n",
    "\n",
    " $\\rho = \\frac{\\sum_{i=1}^n(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{{\\sum_{i=1}^n(x_i - \\bar{x})^2}}\\sqrt{{\\sum_{i=1}^n(y_i - \\bar{y})^2}}}$\n",
    "\n",
    "where $x_i$ is the observation value and $y_i$ is the model value at time or location $i$. $\\bar{x}$ and $\\bar{y}$ are the averages of the vectors $\\bf{x}$ and $\\bf{y}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rho(x,y):\n",
    "    num = np.sum((x - np.mean(x))*(y - np.mean(y)))\n",
    "    dem1 = np.sum((x - np.mean(x))**2)**0.5\n",
    "    dem2 = np.sum((y - np.mean(y))**2)**0.5\n",
    "    return num/dem1/dem2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the time series\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "i = 0\n",
    "for var in vars:\n",
    "    i += 1\n",
    "    plt.subplot(2,2,i)\n",
    "    data1 = np.mean(np.mean(output_gfdl[var][m_gfdl,:,:],axis=1),axis=1)\n",
    "    plt.plot(output_gfdl['dates'][m_gfdl],data1,lw=3)\n",
    "    data2 = np.mean(np.mean(output_era[var][m_era,:,:],axis=1),axis=1)\n",
    "    plt.plot(output_era['dates'][m_era],data2,lw=3)\n",
    "    plt.title(info[var]['title'],fontsize=20)\n",
    "    plt.xticks(fontsize=15,rotation=35)\n",
    "    plt.yticks(fontsize=15)\n",
    "    #Calculate root squared mean error\n",
    "    metric = calculate_rho(data1,data2)\n",
    "    plt.text(0.3,0.9,r'$\\rho$: %.2f' % metric,horizontalalignment='center',verticalalignment='center', \n",
    "             transform=plt.gca().transAxes,fontsize=20)\n",
    "    if i == 1:plt.legend(['GFDL AM4','ERA-Interim'],fontsize=10)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are entire books on performance metrics/statistical tests. They all have their specific purpose. Don't use a performance metric unless you understand what it means! We will cover more as we make our way through the course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some metrics are simple and others are fairly involved. You could spend your time assembling a library of metrics or you could just find a Python package that already has it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Package for model evaluation in Python?: Scipy is the first stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://www.fullstackpython.com/img/logos/scipy.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scipy is a library that contains several toolboxes. \n",
    "\n",
    "* File input/output: **scipy.io**\n",
    "* Special functions: **scipy.special**\n",
    "* Linear algebra operations: **scipy.linalg**\n",
    "* Interpolation: **scipy.interpolate**\n",
    "* Optimization and fit: **scipy.optimize**\n",
    "* Statistics and random numbers: **scipy.stats**\n",
    "* Numerical integration: **scipy.integrate**\n",
    "* Fast Fourier transforms: **scipy.fftpack**\n",
    "* Signal processing: **scipy.signal**\n",
    "* Image manipulation: **scipy.ndimage**\n",
    "\n",
    "Source: http://scipy-lectures.org/intro/scipy.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe width=\"939\" height=\"528\" src=\"https://docs.scipy.org/doc/scipy/reference/stats.html\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We are going to dig more formally intro Probability and Statistics next week. We will revisit many of these functions and probability distributions at that point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Revisit the Pearson correlation with Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Compare the time series\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "i = 0\n",
    "for var in vars:\n",
    "    i += 1\n",
    "    plt.subplot(2,2,i)\n",
    "    data1 = np.mean(np.mean(output_gfdl[var][m_gfdl,:,:],axis=1),axis=1)\n",
    "    plt.plot(output_gfdl['dates'],data1,lw=3)\n",
    "    data2 = np.mean(np.mean(output_era[var][m_era,:,:],axis=1),axis=1)\n",
    "    plt.plot(output_era['dates'][m_era],data2,lw=3)\n",
    "    plt.title(info[var]['title'],fontsize=20)\n",
    "    plt.xticks(fontsize=15,rotation=35)\n",
    "    plt.yticks(fontsize=15)\n",
    "    #Calculate root squared mean error\n",
    "    metric = scipy.stats.pearsonr(data1,data2)[0]\n",
    "    plt.text(0.3,0.9,r'$\\rho$: %.2f' % metric,horizontalalignment='center',verticalalignment='center', \n",
    "             transform=plt.gca().transAxes,fontsize=20)\n",
    "    if i == 1:plt.legend(['GFDL AM4','ERA-Interim'],fontsize=10)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What about Durham, NC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's first retrieve the ilat/ilon\n",
    "file = '/data/era-interim/era_interim_monthly_197901_201512_upscaled.nc_ann'\n",
    "fp = nc.Dataset(file)\n",
    "lats = fp['lat'][:]\n",
    "lons = fp['lon'][:]\n",
    "lat = 35.9940\n",
    "lon = -78.8986\n",
    "ilat = np.argmin(np.abs(lats - lat))\n",
    "ilon = np.argmin(np.abs(lons - lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the time series\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "i = 0\n",
    "for var in vars:\n",
    "    i += 1\n",
    "    plt.subplot(2,2,i)\n",
    "    data1 = output_gfdl[var][m_gfdl,ilat,ilon]\n",
    "    plt.plot(output_gfdl['dates'][m_gfdl],data1,lw=3)\n",
    "    data2 = output_era[var][m_era,ilat,ilon]\n",
    "    plt.plot(output_era['dates'][m_era],data2,lw=3)\n",
    "    plt.title(info[var]['title'],fontsize=20)\n",
    "    plt.xticks(fontsize=15,rotation=35)\n",
    "    plt.yticks(fontsize=15)\n",
    "    #Calculate root squared mean error\n",
    "    rho = scipy.stats.pearsonr(data1,data2)[0]\n",
    "    bias = calculate_bias(data1,data2)\n",
    "    rmse = calculate_rmse(data1,data2)\n",
    "    plt.text(0.5,0.1,r'$\\rho$: %.2f, bias: %.2f, rmse: %.2f' % (rho,bias,rmse),\n",
    "             horizontalalignment='center',verticalalignment='center', \n",
    "             transform=plt.gca().transAxes,fontsize=15)\n",
    "    if i == 1:plt.legend(['GFDL AM4','ERA-Interim'],fontsize=10)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Be skeptical of localized climate predictions... Things are improving but we still have a very long ways to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Localized metrics over the globe\n",
    "\n",
    "In other words, can we determine the localized performance of the climate model over the entire globe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We just need to iterate per cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the output metrics dictionary\n",
    "metrics = {}\n",
    "#Iterate per variable\n",
    "for var in ['t_ref',]:\n",
    "    print(var)\n",
    "    #Initialize the global array per variable and metric to hold the computed values\n",
    "    if var not in metrics:\n",
    "        metrics[var] = {'rho':np.zeros((output_era[var].shape[1],output_era[var].shape[2])),\n",
    "                        'bias':np.zeros((output_era[var].shape[1],output_era[var].shape[2])),\n",
    "                        'rmse':np.zeros((output_era[var].shape[1],output_era[var].shape[2]))}\n",
    "    #Iterate per grid cell\n",
    "    for i in range(output_era[var].shape[1]):\n",
    "        for j in range(output_era[var].shape[2]):\n",
    "            data_era = output_era[var][m_era,i,j]\n",
    "            data_gfdl = output_gfdl[var][m_gfdl,i,j]\n",
    "            metrics[var]['rho'][i,j] = calculate_rho(data_gfdl,data_era)\n",
    "            metrics[var]['rmse'][i,j] = calculate_rmse(data_gfdl,data_era)\n",
    "            metrics[var]['bias'][i,j] = calculate_bias(data_gfdl,data_era)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.s. There are much faster ways to do this. We might get to it at the end of the course. Hint: [Numba](https://numba.pydata.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "rise": "scroll"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
