{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the United States, soils are classified using the [USDA soil taxonomy](https://www.nrcs.usda.gov/Internet/FSE_DOCUMENTS/nrcs142p2_051232.pdf). Within the USDA soil taxonomy, the most general level is the taxonomic order. In this assignment we will be using a suite of decision-tree based classification algorithms to create spatial maps of taxonomic order over western Illinois. The point observations come from the [NASIS database](https://www.nrcs.usda.gov/wps/portal/nrcs/detail/soils/survey/tools/?cid=nrcs142p2_053552) while the environmental predictors come from Sentinel 2, the National Elevation Data, and the National Land Cover database.\n",
    "\n",
    "For this homework, all the data have already been subsetted and preprocessed and are compiled in the following NetCDF file `/data/HW/HW7.nc`. The file is split into two groups: predictors and observations. The predictors group contains a set of 1 arcsec maps for the domain and the observations group contains the in-situ taxonomic order observations with their associated geographic coordinates. Although not required, we recommend using xarray to read in these data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Environmental predictors (5 pts)\n",
    "\n",
    "Read in and create maps of all the predictors. Describe any apparent discrepancies in scale between the maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extract each site's collocated predictors (5 pts)\n",
    "\n",
    "Read in the in-situ observations and assemble the corresponding predictors for each site. Finally, create the $\\mathbf{X}$ array of predictors and the $\\mathbf{y}$ array of observed taxonomic orders. This dataset will be used throughout the rest of the assignment to fit and evaluate the classification algorithms. Note that you will need to convert the taxonomic order names to integers for use in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fit and evaluate a decision tree (10 pts)\n",
    "\n",
    "Use the validation set approach to divide your data into training and test datasets. Each dataset should contain 50% of the data. Then fit a Decision tree using the training data and evaluate its accuracy for both the training and test datasets. Explain the differences in accuracy when evaluating the training and test datasets. To ensure reproduceability, when initializing the decision tree, set the random_state to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Perform 10-fold cross validation (10 pts)\n",
    "\n",
    "Using  all the site data, perform a 10-fold cross validation of the decision tree and compare the results to the previous exercise. Set random_state to 1 and set shuffle to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Moving to ensemble tree methods (10 pts)\n",
    "\n",
    "Setting the number of decision trees to 100, perform a 10-fold cross validation using Bagging, Random Forests, and Gradient Boosting. Discuss how the results of these different ensemble methods vary amongst themselves. Also compare the results to those obtained from a single decision tree. Remember to set random_state to 1 and shuffle to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Out of bag score (10 pts)\n",
    "\n",
    "Using 100 trees, fit a Random Forest to the entire sites dataset and report the out of bag score. Compare that result to that obtained from the cross validation. Explain what the out of bag score is and how it can be more useful than cross validation. Remember to set random_state to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Optimal number of trees (10 pts)\n",
    "\n",
    "Iterate through the number of decision trees varying from 1 to 100 in 1 tree increments. For each iteration, fit a Random Forest and append the corresponding out of bag score to a list. Plot the out of bag score as a function of the number of decision trees. What do you learn about the optimal number of trees for this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Plot the predictions (10 pts)\n",
    "\n",
    "After fitting a random forest with 100 trees, plot a map of the entire region of the predicted taxonomy order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Feature importance (10 pts)\n",
    "\n",
    "Plot the feature importance of the predictors in the previously fitted Random Forest and describe the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Confidence in the predictions (10 pts)\n",
    "\n",
    "Assemble the maps of probabilities per taxonomic order from the previously fitted Random Forest. Then for each cell, sort these data from highest to lowest. Finally, for each cell, compute the difference between the highest and second highest probabilities. Plot the map of this difference. What do you learn from this map? What could explain the regions where the difference in probability of the first and second most probable taxonomic orders is low?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Dimensionality reduction (10 pts)\n",
    "\n",
    "After standardizing the data, use PCA to reduce the number of predictors of the sites dataset down to 5. What is the total explained variance when considering only the top 5 principal components? Then fit a Random forest to these data with 100 decision trees and report the out of bag score. What does this result tell us about the utility of dimensionality reduction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
